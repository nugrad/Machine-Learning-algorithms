{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit Learn Library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn (sklearn) is a library in Python that provides many unsupervised and supervised learning algorithms. It’s built upon some of the technology you might already be familiar with, like NumPy, pandas, and Matplotlib.\n",
    "\n",
    "The functionality that scikit-learn provides include:\n",
    "\n",
    " - Regression, including Linear and Logistic Regression algorithms etc\n",
    " - Classification, including K-Nearest Neighbors algorithms etc\n",
    " - Clustering, including K-Means and K-Means++ etc\n",
    " - Model selection\n",
    " - Preprocessing, including Min-Max Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine learning has three types :\n",
    " - Supervised machine learning (class/label/target is given)\n",
    " - Un-supervised machine learning (class/label/target is not given)\n",
    " - Reinforcement Learning (reward based)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Supervised algorithms:</b>\n",
    "   \n",
    "   - <b>Classification algorithms</b> (like KNN, Decision Tree, Naive Bayes etc)\n",
    "      \n",
    "   - <b>Regression</b> (like linear regression, logistic regression etc)\n",
    "      \n",
    "      <br>\n",
    "      \n",
    "<b>Unsupervised algorithms:</b>\n",
    "   - <b>Clustering Algorithms</b> (like kmeans, kmeans++ etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning Algorithms\n",
    "\n",
    "## K-Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import pandas\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal-length</th>\n",
       "      <th>sepal-width</th>\n",
       "      <th>petal-length</th>\n",
       "      <th>petal-width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal-length  sepal-width  petal-length  petal-width           class\n",
       "0             5.1          3.5           1.4          0.2     Iris-setosa\n",
       "1             4.9          3.0           1.4          0.2     Iris-setosa\n",
       "2             4.7          3.2           1.3          0.2     Iris-setosa\n",
       "3             4.6          3.1           1.5          0.2     Iris-setosa\n",
       "4             5.0          3.6           1.4          0.2     Iris-setosa\n",
       "..            ...          ...           ...          ...             ...\n",
       "145           6.7          3.0           5.2          2.3  Iris-virginica\n",
       "146           6.3          2.5           5.0          1.9  Iris-virginica\n",
       "147           6.5          3.0           5.2          2.0  Iris-virginica\n",
       "148           6.2          3.4           5.4          2.3  Iris-virginica\n",
       "149           5.9          3.0           5.1          1.8  Iris-virginica\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets apply K-Nearest Neighbour Algorithm on Iris Flower dataset\n",
    "# Iris flower dataset has four attributes (first four columns) based on which it tells which type of flower it is out of total 3 types\n",
    "\n",
    "names = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'class']\n",
    "dataset = pandas.read_csv(r\"C:\\Users\\sohai\\Desktop\\iris.data\", names=names)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "Iris-setosa        50\n",
       "Iris-versicolor    50\n",
       "Iris-virginica     50\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.groupby('class').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In X, we are having first four columns of every row i-e sepal_length, sepal_width, petal_length, petal_width\n",
    "# In Y, we are having 4th column of every row which is basically class/label i-e Iris satosa, Iris verginica or Iris versicolor \n",
    "\n",
    "array = dataset.values\n",
    "X = array[:,0:4]\n",
    "Y = array[:,4]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  [[6.2 2.8 4.8 1.8]\n",
      " [5.7 2.6 3.5 1.0]\n",
      " [4.6 3.6 1.0 0.2]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [4.8 3.0 1.4 0.3]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [7.1 3.0 5.9 2.1]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.5 3.0 5.5 1.8]\n",
      " [5.7 3.0 4.2 1.2]\n",
      " [5.0 3.3 1.4 0.2]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [6.0 2.2 4.0 1.0]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [4.3 3.0 1.1 0.1]\n",
      " [6.3 3.3 6.0 2.5]\n",
      " [5.5 2.4 3.7 1.0]\n",
      " [5.0 2.0 3.5 1.0]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.0 3.4 1.6 0.4]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [5.0 3.5 1.6 0.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [7.2 3.2 6.0 1.8]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.8 4.0 1.2 0.2]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [5.7 2.5 5.0 2.0]\n",
      " [4.8 3.0 1.4 0.1]\n",
      " [6.5 3.0 5.8 2.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [6.7 3.0 5.2 2.3]\n",
      " [6.1 3.0 4.6 1.4]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [7.0 3.2 4.7 1.4]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [6.5 3.0 5.2 2.0]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [4.9 2.4 3.3 1.0]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [5.6 3.0 4.1 1.3]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [7.9 3.8 6.4 2.0]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [5.1 2.5 3.0 1.1]\n",
      " [5.0 3.4 1.5 0.2]\n",
      " [7.7 2.8 6.7 2.0]\n",
      " [7.6 3.0 6.6 2.1]\n",
      " [5.0 3.2 1.2 0.2]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.1 2.8 4.0 1.3]\n",
      " [6.3 2.5 5.0 1.9]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [5.0 2.3 3.3 1.0]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.6 2.8 4.9 2.0]\n",
      " [4.9 3.0 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [6.0 2.7 5.1 1.6]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.0 3.6 1.4 0.2]\n",
      " [4.4 3.0 1.3 0.2]\n",
      " [6.0 2.9 4.5 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [5.9 3.0 4.2 1.5]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.8 3.0 5.5 2.1]\n",
      " [5.5 2.3 4.0 1.3]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.6 3.0 4.4 1.4]\n",
      " [5.1 3.5 1.4 0.2]\n",
      " [7.7 3.0 6.1 2.3]\n",
      " [6.1 3.0 4.9 1.8]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [6.5 3.2 5.1 2.0]\n",
      " [5.5 2.5 4.0 1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [5.8 2.6 4.0 1.2]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [5.8 2.7 4.1 1.0]\n",
      " [5.0 3.0 1.6 0.2]]\n",
      "Y_train :  ['Iris-virginica' 'Iris-versicolor' 'Iris-setosa' 'Iris-virginica'\n",
      " 'Iris-versicolor' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-virginica' 'Iris-virginica' 'Iris-versicolor' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-versicolor' 'Iris-setosa' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-virginica' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-virginica' 'Iris-setosa' 'Iris-virginica'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-versicolor' 'Iris-virginica'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-setosa' 'Iris-virginica'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-virginica' 'Iris-virginica'\n",
      " 'Iris-setosa' 'Iris-virginica' 'Iris-setosa' 'Iris-versicolor'\n",
      " 'Iris-virginica' 'Iris-versicolor' 'Iris-setosa' 'Iris-versicolor'\n",
      " 'Iris-setosa' 'Iris-virginica' 'Iris-virginica' 'Iris-versicolor'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-versicolor' 'Iris-virginica'\n",
      " 'Iris-setosa' 'Iris-virginica' 'Iris-virginica' 'Iris-versicolor'\n",
      " 'Iris-setosa' 'Iris-versicolor' 'Iris-setosa' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-setosa' 'Iris-setosa' 'Iris-virginica'\n",
      " 'Iris-versicolor' 'Iris-virginica' 'Iris-virginica' 'Iris-versicolor'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-virginica' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-versicolor' 'Iris-virginica' 'Iris-virginica' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-setosa' 'Iris-virginica' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-versicolor' 'Iris-versicolor' 'Iris-virginica'\n",
      " 'Iris-setosa' 'Iris-versicolor' 'Iris-versicolor' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-versicolor' 'Iris-virginica' 'Iris-setosa'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-versicolor' 'Iris-versicolor' 'Iris-setosa'\n",
      " 'Iris-virginica' 'Iris-virginica' 'Iris-versicolor' 'Iris-virginica'\n",
      " 'Iris-setosa' 'Iris-virginica' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-setosa' 'Iris-virginica' 'Iris-versicolor' 'Iris-virginica'\n",
      " 'Iris-versicolor' 'Iris-setosa']\n",
      "X_test :  [[5.9 3.0 5.1 1.8]\n",
      " [5.4 3.0 4.5 1.5]\n",
      " [5.0 3.5 1.3 0.3]\n",
      " [5.6 3.0 4.5 1.5]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.7 3.0 5.0 1.7]\n",
      " [6.0 3.4 4.5 1.6]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [6.0 2.2 5.0 1.5]\n",
      " [7.2 3.0 5.8 1.6]\n",
      " [6.0 3.0 4.8 1.8]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.7 3.1 5.6 2.4]]\n",
      "Y_test :  ['Iris-virginica' 'Iris-versicolor' 'Iris-setosa' 'Iris-versicolor'\n",
      " 'Iris-virginica' 'Iris-setosa' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-setosa' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-setosa' 'Iris-virginica' 'Iris-setosa' 'Iris-versicolor'\n",
      " 'Iris-virginica' 'Iris-virginica' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-versicolor' 'Iris-virginica' 'Iris-versicolor' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-virginica' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-virginica' 'Iris-virginica']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "t_size = 0.20   # training size is 0.2 (20 percent), testing size will be automatically set to 1-0.2 = 0.8 (80 percent) \n",
    "seed = 7        #if this seed is set to any constant number then it will generate same random numbers every time \n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=t_size,random_state=seed) #dividing into training and testing\n",
    "\n",
    "\n",
    "#check by printing what data came into these four variables\n",
    "\n",
    "print(\"X_train: \", X_train)\n",
    "print(\"Y_train : \", Y_train)\n",
    "print(\"X_test : \", X_test)\n",
    "print(\"Y_test : \", Y_test)\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=2) # two nearest neighbors i-e K=2\n",
    "knn.fit(X_train, Y_train)      # training the model\n",
    "predictions = knn.predict(X_test)  # now testing on test data to get class of test data\n",
    "print((accuracy_score(Y_test, predictions))) # comparing results predicted by model with actual to get accuracy score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00         7\n",
      "Iris-versicolor       0.86      1.00      0.92        12\n",
      " Iris-virginica       1.00      0.82      0.90        11\n",
      "\n",
      "       accuracy                           0.93        30\n",
      "      macro avg       0.95      0.94      0.94        30\n",
      "   weighted avg       0.94      0.93      0.93        30\n",
      "\n",
      "[[ 7  0  0]\n",
      " [ 0 12  0]\n",
      " [ 0  2  9]]\n"
     ]
    }
   ],
   "source": [
    "# evaluation metrics other than accuracy\n",
    "print((classification_report(Y_test, predictions)))   \n",
    "print(confusion_matrix(Y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN using validation technique as \"k-fold cross validation\" instead of \"train-test split\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9800000000000001\n"
     ]
    }
   ],
   "source": [
    "#Suppose we are applying 5-fold cross validation\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=10)\n",
    "accuracy = cross_val_score(knn, X, Y, cv=5)\n",
    "accuracy = np.mean(accuracy)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tasks :"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Q1)</b> Occupancy dataset contains four attributes i-e \"Humidity, Light, CO2 and Humidity ratio\". Apply KNN to find if occupancy is possible or not (0 or 1) based on \"Humidity, Light and Humidity Ratio\" only. Train on \"Occupancy_train.txt\" and Test on \"Occupancy_test.txt\".\n",
    "You need to do the following then :\n",
    "- Run this KNN Algorithm for <b>n_neighbors</b> (K) from 1 to 10. You will get 10 different accuracies. Print all the   accuracies. Then print the highest accuracy and also the value of K at which you got the highest accuracy.\n",
    "- Run this KNN Algorithm for different random seed values from 1 to 10. Print all accuracies and then print the highest\n",
    "\n",
    "<b>Q2)</b> Now instead of using built-in library, write your own code for kNN classifier from scratch. Run on iris dataset. Use 80/20 split. Print accuracy and confusion matrix at the end. You must use the following chi squared distance function :\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
