{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de2795d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "matplotlib.rcParams.update({'font.size': 12})\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b3f29236",
   "metadata": {},
   "outputs": [],
   "source": [
    "names=['OSM_ID', 'LONGITUDE', 'LATITUDE', 'ALTITUDE']\n",
    "df=pd.read_csv(r'C:\\Users\\User\\OneDrive\\Desktop\\3D_spatial_network.txt', names =names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8b060162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OSM_ID</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>ALTITUDE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>144552912</td>\n",
       "      <td>9.349849</td>\n",
       "      <td>56.740876</td>\n",
       "      <td>17.052772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>144552912</td>\n",
       "      <td>9.350188</td>\n",
       "      <td>56.740679</td>\n",
       "      <td>17.614840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>144552912</td>\n",
       "      <td>9.350549</td>\n",
       "      <td>56.740544</td>\n",
       "      <td>18.083536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144552912</td>\n",
       "      <td>9.350806</td>\n",
       "      <td>56.740485</td>\n",
       "      <td>18.279465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>144552912</td>\n",
       "      <td>9.351053</td>\n",
       "      <td>56.740486</td>\n",
       "      <td>18.422974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434869</th>\n",
       "      <td>93323205</td>\n",
       "      <td>9.936479</td>\n",
       "      <td>57.499686</td>\n",
       "      <td>20.134033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434870</th>\n",
       "      <td>93323205</td>\n",
       "      <td>9.935696</td>\n",
       "      <td>57.499426</td>\n",
       "      <td>20.580884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434871</th>\n",
       "      <td>93323205</td>\n",
       "      <td>9.935009</td>\n",
       "      <td>57.499282</td>\n",
       "      <td>19.733141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434872</th>\n",
       "      <td>93323209</td>\n",
       "      <td>9.943479</td>\n",
       "      <td>57.495919</td>\n",
       "      <td>24.027015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434873</th>\n",
       "      <td>93323209</td>\n",
       "      <td>9.943451</td>\n",
       "      <td>57.496270</td>\n",
       "      <td>24.635285</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>434874 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           OSM_ID  LONGITUDE   LATITUDE   ALTITUDE\n",
       "0       144552912   9.349849  56.740876  17.052772\n",
       "1       144552912   9.350188  56.740679  17.614840\n",
       "2       144552912   9.350549  56.740544  18.083536\n",
       "3       144552912   9.350806  56.740485  18.279465\n",
       "4       144552912   9.351053  56.740486  18.422974\n",
       "...           ...        ...        ...        ...\n",
       "434869   93323205   9.936479  57.499686  20.134033\n",
       "434870   93323205   9.935696  57.499426  20.580884\n",
       "434871   93323205   9.935009  57.499282  19.733141\n",
       "434872   93323209   9.943479  57.495919  24.027015\n",
       "434873   93323209   9.943451  57.496270  24.635285\n",
       "\n",
       "[434874 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8befde30",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: 'continuous'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-1a2e402057bb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-20-1a2e402057bb>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m     \u001b[0mmodel1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m     \u001b[0mmodel1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[1;31m# Prediction on test set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1345\u001b[0m                                    \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"C\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1346\u001b[0m                                    accept_large_sparse=solver != 'liblinear')\n\u001b[1;32m-> 1347\u001b[1;33m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1348\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\multiclass.py\u001b[0m in \u001b[0;36mcheck_classification_targets\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    181\u001b[0m     if y_type not in ['binary', 'multiclass', 'multiclass-multioutput',\n\u001b[0;32m    182\u001b[0m                       'multilabel-indicator', 'multilabel-sequences']:\n\u001b[1;32m--> 183\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Unknown label type: %r\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown label type: 'continuous'"
     ]
    }
   ],
   "source": [
    "# Importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings( \"ignore\" )\n",
    "  \n",
    "# to compare our model's accuracy with sklearn model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Logistic Regression\n",
    "class LogitRegression() :\n",
    "    def __init__( self, learning_rate, iterations ) :        \n",
    "        self.learning_rate = learning_rate            \n",
    "        self.iterations = iterations\n",
    "          \n",
    "    # Function for model training    \n",
    "    def fit( self, X, Y ) :        \n",
    "        # no_of_training_examples, no_of_features    \n",
    "        self.m, self.n = X.shape \n",
    "        # weight initialization        \n",
    "        self.W = np.zeros( self.n )  \n",
    "        self.b = 0        \n",
    "        self.X = X        \n",
    "        self.Y = Y\n",
    "        x_mean=[]\n",
    "        for i in range(0,self.n):\n",
    "            x_mean.append(np.mean(X[:,i]))\n",
    "            \n",
    "        y_mean = np.mean(Y)\n",
    "        for k in range(self.n):\n",
    "            numerator = 0\n",
    "            denominator = 0\n",
    "            for i in range(self.m):\n",
    "                numerator += (X[i][k] - x_mean[k]) * (Y[i] - y_mean)\n",
    "                denominator += (X[i][k] - x_mean[k]) ** 2\n",
    "            self.W=numerator / denominator\n",
    "            self.b = y_mean - (self.W * x_mean[k])\n",
    "        \n",
    "    \n",
    "        # gradient descent learning\n",
    "                  \n",
    "        for i in range( self.iterations ) :            \n",
    "            self.update_weights()            \n",
    "        return self\n",
    "      \n",
    "    # Helper function to update weights in gradient descent\n",
    "      \n",
    "    def update_weights( self ) :\n",
    "        s=self.b[0]\n",
    "        A =  self.X.dot( self.W )\n",
    "        A=A+s\n",
    "#         # calculate gradients        \n",
    "        tmp = ( A - self.Y.T )        \n",
    "        tmp = np.reshape( tmp, self.m )        \n",
    "        dW = np.dot( self.X.T, tmp ) / self.m         \n",
    "        db = np.sum( tmp ) / self.m \n",
    "          \n",
    "#         # update weights    \n",
    "        self.W = self.W - self.learning_rate * dW    \n",
    "        self.b = self.b - self.learning_rate * db\n",
    "          \n",
    "        return self\n",
    "      \n",
    "    # Hypothetical function  h( x ) \n",
    "      \n",
    "    def predict( self, X ) :    \n",
    "        Y =  X.dot( self.W ) + self.b        \n",
    "        return Y\n",
    "  \n",
    "  \n",
    "# Driver code\n",
    "  \n",
    "def main() :\n",
    "      \n",
    "    # Importing dataset    \n",
    "    X = df.iloc[:,:-1].values\n",
    "    Y = df.iloc[:,-1:].values\n",
    "    \n",
    "      \n",
    "    # Splitting dataset into train and test set\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 1/3, random_state = 0 )\n",
    "      \n",
    "    # Model training    \n",
    "    model = LogitRegression( learning_rate = 0.01, iterations = 1000 )\n",
    "      \n",
    "    model.fit( X_train, Y_train )\n",
    "      \n",
    "    # Prediction on test set\n",
    "    Y_pred = model.predict( X_test )  \n",
    "      \n",
    "#     # measure performance    \n",
    "    correctly_classified = 0 \n",
    "      \n",
    "#     # counter    \n",
    "    count = 0    \n",
    "    for count in range( np.size( Y_pred ) ) :  \n",
    "        \n",
    "        if Y_test[count] == Y_pred[count] :            \n",
    "            correctly_classified = correctly_classified + 1\n",
    "          \n",
    "        count = count + 1\n",
    "          \n",
    "    print( \"Accuracy on test set by our model       :  \", ( \n",
    "      correctly_classified / count ) * 100 )\n",
    "  \n",
    "  \n",
    "if __name__ == \"__main__\" :     \n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c3dbb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c474c9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889576e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
